# 2026-02-19 Memory Log

## OpenClaw VM Creation on Proxmox (✅ COMPLETE)

### Created VM 102 "openclaw-vm"
- **Specs:** 4 vCPUs, 8GB RAM
- **Image:** Ubuntu 24.04 LTS cloud image (`/var/lib/vz/template/iso/ubuntu-24.04-cloudimg.qcow2`)
- **Disk:** `local:102/vm-102-disk-0.qcow2` (3.5GB)
- **Network:** virtio, bridge=vmbr0, MAC: `BC:24:11:EF:4B:FA`
- **User:** fahmy (with SSH keys from root@pve)
- **Cloud-init:** DHCP, auto-upgrade enabled
- **Status:** VM started, waiting for cloud-init to complete

### ✅ COMPLETED (2026-02-19 15:58 UTC)
- VM IP: **192.168.178.110**
- SSH: `ssh fahmy@192.168.178.110`
- OpenClaw v2026.2.17 installed and running
- Systemd service enabled (auto-starts on boot)
- Dashboard: http://192.168.178.110:18789/
- **Model:** kimi-k2.5:cloud (Ollama at 192.168.178.38:11434 - Proxmox host)
- **Channels:** Telegram (bot token configured)

### Lessons Learned
- **Disk sizing:** Ubuntu cloud images have small partition tables (~2.5GB). Use `qm resize` BEFORE first boot, and the filesystem will auto-grow with cloud-init.
- **Finding VM IPs:** DHCP leases at `/var/lib/misc/dnsmasq.leases` or use `ip neigh show` with MAC address matching.
- **OpenClaw config location:** `~/.openclaw/openclaw.json` (JSON5 format) — NOT `/etc/openclaw/config.yaml`
- **Ollama model config format:** Use `id` and `name` fields, not `ref` and `alias`:
  ```json5
  models: {
    providers: {
      ollama: {
        baseUrl: "http://192.168.178.38:11434",
        apiKey: "ollama-local",
        models: [{ id: "kimi-k2.5:cloud", name: "Kimi K2.5" }]
      }
    }
  }
  ```
- **Local Ollama requires apiKey:** Even for local instances, add `"apiKey": "ollama-local"` and `env.OLLAMA_API_KEY: "ollama-local"` to avoid "No API key found" error.
- **Systemd service user:** Must match config file ownership. Running as `root` but config in `/home/fahmy/.openclaw/` causes "Missing config" error. Fixed by setting `User=fahmy` in systemd service file.

### Telegram Bot
- **Bot:** @Oberwart2Bot (token: `8509601248:AAEyXkoVCaxUCbtKNECkoMlSk6BNOIqymx8`)
- **Status:** Operational as of 2026-02-19 16:20 CET

### Deployment Template
- **Saved:** `~/workspace/templates/openclaw-vm-deployment.md`
- Contains: Full VM creation commands, config template, systemd service, troubleshooting guide, quick-deploy script
- Use for future OpenClaw VM deployments to avoid repeating troubleshooting steps

### Commands Used
```bash
# Download Ubuntu cloud image
wget -O /var/lib/vz/template/iso/ubuntu-24.04-cloudimg.qcow2 \
  https://cloud-images.ubuntu.com/noble/current/noble-server-cloudimg-amd64.img

# Create VM
/usr/sbin/qm create 102 --name "openclaw-vm" --memory 8192 --cores 4 --cpu host \
  --net0 virtio,bridge=vmbr0 --ostype l26 --scsihw virtio-scsi-pci \
  --bootdisk scsi0 --serial0 socket --vga serial0 --agent enabled=1

# Import disk
/usr/sbin/qm importdisk 102 /var/lib/vz/template/iso/ubuntu-24.04-cloudimg.qcow2 local --format qcow2

# Configure VM
/usr/sbin/qm set 102 --scsi0 local:102/vm-102-disk-0.qcow2
/usr/sbin/qm set 102 --ciuser fahmy
/usr/sbin/qm set 102 --sshkeys /root/.ssh/authorized_keys
/usr/sbin/qm set 102 --ipconfig0 ip=dhcp
/usr/sbin/qm set 102 --ide2 local:cloudinit
/usr/sbin/qm set 102 --boot order=scsi0

# Start VM
/usr/sbin/qm start 102
```

---

## Final Status (16:42 CET)
✅ OpenClaw VM fully operational
- Telegram bot responding
- Model: kimi-k2.5:cloud via Ollama
- Deployment template saved for future use

### VM Disk Details (16:46 CET)
- **Virtual disk:** 20GB (Ubuntu cloud image auto-grows filesystem)
- **Actual qcow2 size:** 4.4GB on Proxmox storage (thin-provisioned)
- **Partition layout:** sda1 (19G, root), sda15 (106M, EFI), sda16 (913M, /boot), sda14 (4M, BIOS)

### Disk Expansion Procedure (16:48 CET)
```bash
# On Proxmox - resize virtual disk (e.g., add 30GB)
qm resize 102 scsi0 +30G

# Ubuntu cloud images auto-grow filesystem on next boot
# If manual resize needed inside VM:
sudo growpart /dev/sda 1
sudo resize2fs /dev/sda1
```
- Thin provisioning: Can expand anytime without downtime (reboot recommended for cleanest grow)

---

## Homarr Dashboard (17:15 CET)
- **Purpose:** Central dashboard for Proxmox services
- **Location:** `/opt/homarr` on Proxmox host (pve)
- **URL:** http://192.168.178.38:7575
- **Docker compose:** Standard setup with hex encryption key
- **Status:** ✅ Running

### Docker Compose Config
```yaml
services:
  homarr:
    image: ghcr.io/homarr-labs/homarr:latest
    container_name: homarr
    restart: unless-stopped
    environment:
      - SECRET_ENCRYPTION_KEY=<64-char-hex>
      - TZ=Europe/Vienna
    volumes:
      - ./config:/app/data
      - ./icons:/app/public/icons
    ports:
      - "7575:7575"
```

### Dashboard Options Considered
- **Homarr** ✅ - Modern, Proxmox integration, chosen
- **Dashy** - Feature-rich, highly customizable
- **Heimdall** - Simple, elegant
- **CasaOS** - Full cloud OS with app store

---

## Paperless-ngx Discovery (18:54 CET)
- **Status:** ✅ Running on Proxmox host
- **URL:** http://192.168.178.38:8000
- **API:** Protected (requires authentication)
- **Note:** Same host as Ollama (192.168.178.38)

---

## Paperless Stack Deployment Script (20:02 CET)

### Created Portable One-Liner Installer
- **Script:** `/home/openclaw/.openclaw/workspace/scripts/deploy-paperless-stack.sh`
- **Purpose:** Deploy Paperless-ngx + PaperlessGPT + Paperless-AI on any Linux system
- **Based on:** Working production setup at `/opt/paperless` on Proxmox host

### Stack Components
| Service | Port | Image | Purpose |
|---------|------|-------|---------|
| paperless-ngx | 8000 | ghcr.io/paperless-ngx/paperless-ngx:latest | Document management |
| paperless-gpt | 8081 | icereed/paperless-gpt:latest | LLM OCR & tagging |
| paperless-ai | 3000 | clusterzx/paperless-ai:latest | Auto-classification & RAG |
| postgres | - | postgres:16 | Database |
| redis | - | redis:7-alpine | Message broker |

### Production Config Values (extracted)
- **Ollama:** `http://172.19.0.1:11434` (Docker gateway IP for Linux)
- **LLM Model:** `qwen3-vl:235b-cloud` (vision model for OCR + classification)
- **OCR Language:** `deu+eng+ara` (German, English, Arabic)
- **Timezone:** `Europe/Berlin`
- **PAPERLESS_API_TOKEN:** `84309c0cdca3d992bd54a1603399f29df752d996`

### Custom Prompts (7 templates)
Located at `/opt/paperless/prompts/`:
- `tag_prompt.tmpl` - Smart tag selection from available tags
- `correspondent_prompt.tmpl` - Sender ID (strips GmbH/AG suffixes)
- `title_prompt.tmpl` - Title generation from OCR content
- `document_type_prompt.tmpl` - Classification (Invoice, Contract, etc.)
- `ocr_prompt.tmpl` - High-quality vision OCR transcription
- `created_date_prompt.tmpl` - Date extraction (YYYY-MM-DD)
- `custom_field_prompt.tmpl` - Invoice fields, monetary extraction

### Script Features
- Auto-detects Ollama host (Docker gateway IP on Linux)
- Generates secure random credentials
- Creates all 7 custom prompt templates
- Health-checks services before completion
- Saves credentials to `credentials.txt`
- Configurable via environment variables

### Usage
```bash
# Direct run
sudo bash deploy-paperless-stack.sh

# Custom config
sudo OLLAMA_MODEL=kimi-k2.5:cloud TZ=Europe/Vienna bash deploy-paperless-stack.sh

# One-liner from web
curl -fsSL https://server/deploy-paperless-stack.sh | sudo bash
```

### Linux Docker Networking Note
- `host.docker.internal` does NOT work on Linux (macOS/Windows only)
- Use Docker gateway IP: `ip route show default | awk '/default/ {print $3}'`
- Or `extra_hosts: host.docker.internal:host-gateway` in compose

---

## GitHub Account (20:05 CET)
- **Username:** fahmykhattab
- **Token:** `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`
- **Note:** Use for repo access, deployments, or CI/CD as needed

---

## GitHub Repo Created (20:13 CET)

### paperless-stack
- **URL:** https://github.com/fahmykhattab/paperless-stack
- **Purpose:** One-liner deployment script for Paperless-ngx + PaperlessGPT + Paperless-AI
- **Files:** `deploy-paperless-stack.sh`, `README.md`
- **Install command:** `curl -fsSL https://raw.githubusercontent.com/fahmykhattab/paperless-stack/main/deploy-paperless-stack.sh | sudo bash`
- **Features:**
  - Auto-detects Ollama host (Docker gateway IP for Linux)
  - Generates secure random credentials
  - Includes 7 custom prompt templates for PaperlessGPT
  - Health-checks services before completion